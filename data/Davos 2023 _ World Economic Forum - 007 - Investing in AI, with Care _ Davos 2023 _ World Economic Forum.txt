you all for coming to today's session on French cooking now? You know, I don't need to tell any of you the concept of AI was something that we've been talking about for decades has, in the last couple of months just captured the imagination, I think especially with things like tat GPT, and Dolly, everyone's head is spinning. They're thinking, Oh, wow, I could do this, or this is what it would mean for my business or who I'm kind of worried about that. And there's so many different angles to what's coming. What do we need to do as a society? How does this change jobs? How does this change education? You know, what is going to happen? What should regulation be? And we're going to talk about some of these but one of the specific angles is, what does it mean for investment? And that doesn't just mean but we are going to talk about what kinds of companies should we be investing? What's the time horizon? What's coming sooner, or what's going to take longer? But also, what role do investors play? You know, there's been a lot of talk about, where are the guardrails? You know, how do we make sure the technology serves society? Some of that, obviously, we're in Europe, certainly regulation comes to mind. But investors can play a really big role in saying, this is the kind of thing I would put my money in. And this is the kind of thing I won't. I think there's a ton to talk about. Fortunately, I have an incredible panel of folks who are going to do most of the rest of that talking, and I'm going to try and talk as little as possible. And having just had a brief few moments to catch up with the panel. I think that will be no problem at all. So I'm joined by Jim Brier, the founder and CEO of Briar capital. Hunyadi Dogan, the chairwoman of hepsia burrata, which in Turkish means remind me everything is here, which seems very apt for the conversation, we're having. Tom Siebel, who started a little company A while back and has another one these days that I'm sure he'll tell us a little bit about. And Lauren Woodman the CEO of data kind, maybe to start things off, you know, everyone comes at this discussion, you know, the topics that I talked about, with a slightly different perspective, briefly talked about sort of how you're coming at this moment. Like, I think we're all in the same moment. But we're all coming to it from a slightly different place. So maybe if you're comfortable, Lauren, we'll start with you and move down this way. Sure. And thank you, my colleagues, this is I think you're right, we're going to have a lively discussion up here. And I think it is a moment in time where we need to have a lively discussion. So did a kind is a nonprofit organization. And we're really committed to using data science and AI in the service of good, right, and how do we how do we drive social impact from the insights that we can derive from data, and data science and AI and machine learning and all of the tools that are becoming available? The challenges is, how do you make sure that we don't leave behind organizations that have huge amounts of data that can actually advance and address some of the societal challenges that we're facing? How do we make sure that as AI is getting developed, we're not losing sight of the fact that there are very good commercial applications. But there's also very good applications in in the world of trying to achieve the sustainable development goals are trying to address poverty or any of these gaps. And it is a complex situation, nonprofits, by and large, don't create software tools, when it's really not our strength. But we do have it and so we have to rely on investors, and we have to rely on on the tech sector. And we have to rely on regulators, you know, to think through sort of what the implications of that are. So I'm glad that there is this moment where we're having this conversation, because there's there are lots and lots of issues to resolve and make sure that we do not lose sight of the good that we can do. Tom, you're obviously not. I mean, I'm sure you have a few dollars left over to invest, but you're primarily running an AI business these days. Talk about the role that the people who fund companies like yours play in sort of shaping that as well as kind of you've been, you know, early in this space. Why did you decide to plunk down the biggest investment you have, which is your time into what you're doing at C three is, as a right, a little context. This is my fourth decade in the information technology industry. I'm a computer scientist from the University of Illinois, did my graduate work in relational database theory got recruited by a small startup with about 20 people called Oracle Corporation. And that turned out to be a pretty good idea. I was ultimately one of the guys who ran that business. I'm frequently asked by the media, what my kind of biggest failures were professionally. It was just It just occurs to me what it was. My biggest failure professionally is when we tried to recruit Jim Brier and Oracle in 1986. When he just graduated from the Harvard Business School, and we failed to do so, okay, that being said, very sad that that is my biggest professional failure. So I was ultimately one of the guys who ran that business. In 1993, we spun out, we thought about the application of information technology and communication technology, to the business processes of daily sales, marketing and customer service. This is when I met Don Kay. And so we started a company called Siebel systems. And we invented the CRM market, as you know, today. So that's about $120 billion business this year, it turned out to be So yeah, CRM turned out to be a reasonably good idea. That was purchased repurchase by my friend Larry Ellison in 2006. Now, as we looked at the world, in 2006, we saw a big step function of technology coming online, in the form of Elastic Cloud computing, at that time at AWS might have been doing a half a million a year in cloud computing, big data, the Internet of Things, and we thought these collectively would enable this new field called Predictive Analytics. So we started this company called C three.ai. Where we're in the business of building enterprise AI applications for oil and gas, defense, intelligence, utilities, healthcare, telecommunications, manufacturing, what have you, rough numbers. When I went to work at the Information Technology Business, globally, it was about a $200 billion business today, I think it serves 7 trillion. When we started building enterprise application software, in the 80s, at places like Oracle and SAP, that turned out to be a pretty good idea. That's about a $600 billion market today enterprise software. And it is predicted that enter the enterprise segment of the AI market that this will be a also a $600 billion market in a few years. So this looks like a this is the fastest growing the market opportunity that I will have seen in my professional career. And hands on a you, in addition to just an amazing pink outfit, you also wear multiple hats, as both running a company in Turkey. And also now, thanks to the success of that investing, where does AI fit in both of those hats that you wear? Sure, thank you. I come from a very different background. Because first from a very different part of the world Turkey. And also I've started my life as an entrepreneur, I still define myself as an entrepreneur, I want to tell you a little bit about HIPAA security group to give you context of what I will say about AI. It's a leading ecommerce platform, we are the first and only NASDAQ listed company out of Turkey. And from day one, when we started the company, despite the atolls of technology disrupt, we said we will use our technology power not to destroy and disrupt and get rid of industries, but instead be a catalyst enable an enabler to the industries including retail, including banking to lead their digital banking transformation. So that is the culture the value with that culture and value. I am mostly concerned about Of course, we'll talk reliability, power, concentration, wealth, concentration of AI. But what we do just to give you an example, what we do in our company, because it comes from our culture. One solid example, five years ago, the woman merchants sharing our GMD was less than 1%. And I said this has to change. So what do we do we start the big program called Tech power to woman and we give incentives we train. But then it wasn't enough. So we said, Okay, we're gonna hack our algorithms. And we will positively discriminate woman merchants so that our BuyBox algorithms doesn't always stay biased. Because the data set is biased. It's always man mode since getting the buy box if we don't interfere. Ai amplifies that. Today. It's almost seven 8% of our GMV it's a big, big jump. So this is a I think you have you know, companies like ours who are not big tech, but who have data and who use technologies like machine learning and AI can make a difference as long as they make sure the model stays with their values. This is what I wanted to share is this stat that we can continue the conversation. Excellent. Jim, you know, one of the things I wanted to make sure is that we had, you know, a successful investor. And I don't know if you know this, but between the two of us, we have a net worth of about 2.9 billion. You've been investing for a while. How are you thinking about AI? Well, thanks for having me. And thanks for Oregon, the 2.9 billion to che, there was a time in 2015. I had been immersed for a couple decades in information technology, social networking, oriented investing. And I was on the board of the Harvard Corporation at that point in time and 11 person board, and we were about to launch a new medical school team search. And our president Drew Faust asked me to be point person from the Corporation on that search. interviewed about about 30 Phenomenal potential Dean's from Hopkins and Stanford and UCLA. You name it, MD Anderson. And I typically ask them, what role will artificial intelligence and computation play in the future of medicine and the future of medical schools. And George Daly, the current dean of Harvard Medical School, was the only one who could eloquently say, without AI and computation, there is absolutely no chance. 10 years from now, the best doctors that are not as good doctors, nurse practitioners, you name it, no one will be able to do the job that they want to do we as patients want to do. So I received a call from a friend Stan Druckenmiller, who had been at Memorial Sloan Kettering for prostate cancer. And he said it was a terrible experience. He safe, it worked. But he said it was just a terrible experience in terms of wait times and data going back and forth. And so I made my first major AI investment in the world of AI meets medicine, by spending nine months negotiating a license, steal a royalty deal, intellectual property rights, from MSK, into a new company. The medical personnel all came from MSK, a couple came from Yale. And my job is to go out there and recruit the very best X alphabet, Microsoft, Apple Mehta, the 30 year olds who don't want to just optimize search engine. And since that time, I've made 12 investments with similar models where it starts. And we'll hear more about it today, with exceptional data that's very unique, can't run good algorithms against data that's not unique. And it just so happens most of the unique healthcare data. It's not in the insurance companies. It's in our best hospitals, mostly research hospitals. It's in the medical schools. And so I've been on a mission for certain forms of cancer, such as prostate and breast, to do whatever I can to eradicate, with these tools in these companies, those types of cancers in the next decade, and we have some promising results. But that's one of the reasons I love what I do. So I'm going to start with you on this question, Jim. But then I want the rest of you to argue with him. So I don't have to what is the role of the investor in this? So we talked initially, you know, I frame, you know, individuals are going to have a right role to play human rights groups, nonprofits, governments, and regulators. What is the role of investors? Should we be counting on the investors to say, this is the kind of company we want? What role do you think you can play in investing in a world that has the AI systems, obviously, clearly, we all want the health challenges and the sustainability challenges. But it also seems a little odd to rely on, you know, investors like yourself, to make sure that it's fair to make sure that it's equitable, that there's not bias. But that doesn't mean there's not a role to play. Where do you see that role? Well, at the end of the day, the job of the venture capitalist is pretty simple. We try to have the ability to look around corners over the next many years and try to identify extraordinarily large markets and constantly be meeting many of the best individuals founders. co founders in the world, we have one in the second row, Jack Henry, the founder, CEO of sandbox, AQ and Jack and I worked for well over a year spinning out sandbox AQ, from Google. In other cases, where I've invested, Tom Siebel was the CEO, I shook his hand and said, I'm in. And then there are the cases like the spinouts, I mentioned, were never before as interdisciplinary communication and understanding been more important, because if you're a great chemist, you don't know necessarily the first thing about machine learning. And if you're that great machine learning person out of Google, you better appreciate the great chemist and biologist. And so really, the biggest challenges in the startups which are in and around AI, is one, from ground up, build what the ethical framework is, don't try to tack it on four or five years later, and have an interdisciplinary group of people who get energized every day about working together, learn when in your world, and one thing you want from the companies is the software that you need that you know, and not just your organization, but all organizations, you need these companies to do it. But but in this broader question of what what should we be relying on the investors for? Help us think, you know, again, what, what should we realistically expect? And where do we have to say, that's not really the role of the investor, and we need some other institution, whether it's regulators or someone else to step in? I don't think we get to wash our hands just because we aren't primarily responsible. And I want to give Jim an enormous amount of credit. Right? I mean, it as you were talking about this, you know, one of the things I was thinking about is nonprofits can't necessarily see around that corner. You know, that's not the roll that we do, we see around different corners, perhaps, you know, and so we rely on investors to see around that corner to think about that, at some level, they are the first line of defense, around making good decisions around how these companies get constructed from the very beginning, it is not okay, to come back later and say, we built this, you know, it's 75%. Right? So let's tweak around the margins that we just can't do that. And frankly, things move so quickly, these days, and there's already such a gap between the sectors that you will never have the social sector be able to catch up, if responsible investors aren't actually being an active part of that conversation. And so, you know, do I think it all sits on their shoulders? Absolutely not. We all have a role to play in this. It's like any other ecosystem, you know, I can't absolve people who do bad things and just leave it to the police to solve it like, No, we all have to be good actors in society. And investors are that first line of defense and saying, how do we actually construct companies construct technologies, that as they continue to evolve, will have at least started off in the right direction? What do you see your responsibility as I mean, I am a tech enthusiast, and I'm an optimist. And I do believe AI can decrease the marginal cost of services to zero and make the quality better. So we can have more of every services, everyone gets access to legal advice, everyone gets access to diagnostic health and more at a lower cost. Or, if we get it wrong, it can be the dystopia of our world, you know, so It's that serious what we are facing. With this context. We have to expect more from investors, we have to expect more from corporate leaders, more from civil society and more from consumer. It can't be, you know, investors simply shouldn't invest in companies that don't have the right internal control mechanisms to serve their values. A consumers should be more informed, more alert, more demanding of what's happening with their data. Corporate Leaders have to be more socially aware, this era of like obsession with profit maximization to be shareholder maximum value maximization to be the only reason that profit companies and regulators should be more involved more up to date. And we will see, like the measurements will be a combination of many, many things. You know, it can be publicly owned algorithms monitoring private algorithms. If it can be equity, ownership, social equity ownership of big tech companies, it can be a change in our social contract, the stigma we give to employment. And statues can change because many jobs will not happen. So it will be a combination of different things. And we should expect all from each part of the society, Tom, a lot of the companies, a lot of the big tech companies have set up these independent advisory groups for ethical AI, they've created frameworks for Responsible AI. So it seems like things are going pretty well, right? I think this topic of ethical AI is very troubling. Okay, and very important, and doesn't get nearly enough bandwidth. Let's go to the let's go to Jim's example. I believe the largest commercial application of AI will be precision medicine heart stop. Okay. And so we have the capability today to aggregate say, the genome sequences and the medical care records of the population of say the United States in a unified federated image, hematology, radiology, pharmacology, health history, genome sequences, the work so that we can now build machine learning models that are enormously efficacious, where we can we will we will combine these systems with these devices, okay. And much of these populations will be in the future we will be wearing devices or have embedded devices that will report on pulse blood chemistry, okay, gut chemistry, okay, brainwaves, what have you. So just so we'll be able to serve historically underserved constituencies we will be able to, it is within our grasp today, for a population the size of France, the UK, United States to engage that in early detection, but disease prediction we can predict with very high levels of precision, who's going to be diagnosed with what disease in the next five years? AI is genome specific medical protocols, AI assisted medicine, this is huge, right? This is all motherhood and apple pie. And so we will deliver, you know, lower cost more efficacious health care, okay, in into a, into a healthier community. Now, what could possibly go wrong? Well, let's, let's think about this. Okay. Now, the idea that, you know, that the whether we have a single care provider, and this is a this is a religious issue, I get it, okay. Or whether we have a kind of a quasi free market system like we do in the United States, where we have, you know, private enterprise, the idea that these, that these people who control these data are going to act beneficially. I mean, you could get over that. Okay, see Facebook for details. Okay. Now, we're going to say, so we will know, with, you know, which of us is going to be diagnosed with a terminal illness in the next three years? I mean, do you want to know that? I'm not sure I do. And how are, are these people going to use these data, if you don't think for a minute that they're going to use not going to use these data to ration healthcare, get over it, because they are okay, they will in the UK, they will in China, and they will in the United States, they're going to decide at this time too old for this procedure or dance to old procedure, it's not in the best interest of the country. So get to the back of the line. So it's, these issues are very, very troubling. Okay, as it relates to that will be the largest application of healthcare, there's a big right now they're putting out a roughly half a billion pound for caremount in the UK, okay to revolutionize that the NHS, which, where we have queues of 7 million people waiting for elective surgery. So, this is very troubling, these issues related to priority, anytime we have the intersection of AI and sociology, it goes real bad, real fast. Okay, where are we, you know, we want to talk about AI and criminal justice, okay, it doesn't we have this problem of, you know, cultural bias that are in these data, and they are in these data. Okay. And, or we want I know, we do a lot of work for in the, for the Department of events, and I was talking we do a lot of work for the Secretary of the Army and the Secretary of army was in my office. And he says, uh, Tom, we want to build a HR system for the Department of the Army, or the US Department of the Army is roughly a million half people writ large by the time you get into the reserves and whatnot. And so this was a system that we're gonna use AI to decide who to promote who decide and I said, you know, Mr. Secretary, we can solve this problem. We're gonna, you know, bust our backs for about six months and we could bring this application into production, but we're not going to touch And my recommendation is you don't touch it either. Because the problem is due to the bias in the data, no matter what the question is, the answer is going to be white male went to West Point. And I said, you know, 2023, this is not going to fly, then you got to read about yourselves on the front page of The New York Times, then we got to get dragged before Congress to testify, and I'm not going with you. So it's, uh, you know, the, the ethical issues are very, very troubling. And now we're looking to regulators to bail us out. And then when we get to regulators, the only thing we have worse than the United States might be the EU. Okay, well, you know, where, you know, we're not we have the solution, you know, is worse than the problem. So this is really problematic, there needs to be a lot more talk about it. And, you know, I don't know how I got off on this Jaguar talking about and be afraid. Anytime we interact, we have the intersect. When we're dealing with physics, and we're dealing with machines, nobody cares. There's no there are no bias in those data. There's just temperature, rotational velocity, torque, what have you, okay, but we're dealing with sociology, it goes, goes to a bad place real fast, be afraid. So be afraid is a great, great place to get to. And I think it is really important, you know, I'm, I want to hold both pieces of the AI opportunity, because it is, it is going to help cure diseases, I'm hoping it will help in some of the problems where we don't have enough human time to solve them. Sustainability being the big one. And I want to hold that if we don't do this, right, we're going to make an even more unequal society. I do want to spend a moment or two on some of those opportunities. And one of the ways this intersects with investors is investors really help us we're, you know, when they do their jobs, well, like Jim, help us with the what is the right time horizon? So I'm curious, you know, what is in the right time horizon? I mean, it seems like, clearly generative AI is having a moment like, and I imagine we're gonna see, I'm already my inbox is filled with pitches of companies are not really doing generative AI telling me they're, you know, teaching computers, emotions, and all these other good things. My sense is artificial general intelligence, you know, probably not where a lot of VC investors are saying, Yep, in seven years, I expect to get a big exit, because big brother's gonna run everything. Where what is in the investor time horizon right now, where are the opportunities for anyone who came to Davos to make a little money? Well, I'll jump in quickly. But I'll start with, I think Tom's profound points around bias. One of my favorite investments of all time, was in 2008, a company called Etsy. And Etsy was a buyer and sellers marketplace, 90% of our employees were female, higher than 90%. Were all the buyers and the sellers of the different goods. And a year into it, it was going well, but several of the other board members said, We're never going to be able to get big enough, if we're just focused on women. And I said, I tend to disagree. And we're going to figure that out. And it turned out a month later, I was up at a Microsoft event. And I was seated next to Jeff Bezos, who had tried to buy et Cie. And my talk to him about this conversation. It's 90% of women, sellers are women, the buyers are women. And he said, we as Amazon cannot replicate that. That's a jewel don't ever stray from that model for Etsy, which brings me full forward. Silicon Valley has done a very, very poor job of promoting, helping leading very talented women and underrepresented minorities. I feel very proud. I recruited Sheryl Sandberg in 2008. to Facebook, my mother who's no longer with us was a genius mathematician. And one thing I'm trying to get right this time, with all the power I might have, is when we're starting companies, there has to be that balance set of viewpoints on day one or day two, otherwise, I won't write the check. Super important. Wow. were you seeing some of the investment opportunities around AI like where, you know, there's a ton of talk but you know, you're writing checks. Where are they going? Thank you. Yeah, we have more investors like you I'm sure we will make a difference. And my friends Philip, also, at KKR. He's done a lot promoting women in private equity investors. So thank you, and investment opportunities. I am still, you know, with what you said, we should be afraid we need to make more talks and what you talk. So I need to just focus on investment opportunities. This is what I want to tell you the current high on generative AI, I am slightly worried that it might distract us from talking, researching investing in context driven AI in causal inference in you know, in common sense in an AI. So, that is I am slightly worried. What I like I see huge opportunities is a if you know, business models that can efficiently scale human judgment insight with AI, that's where I see big opportunities. Not easy, but I think any, any business models that can solve that problem will create significant value. This one is actually for anyone, and I'm curious what you think my gut is, when I see all this really amazing technology, you know, tic tac GPT, for instance. But I think it's indicative of a larger trend of, you know, these AI systems that they're incredibly powerful, but we also we don't know how they work. We don't know how they think, is it reasonable to think we should be investing in AI that is transparent and explainable or as an investor? Is it just more expensive, and ultimately, someone's going to do the same thing? You know, we do have this confidently wrong problem right now, where, you know, if I put something into chat, GBT, it's going to be incredibly impressive. It's not going to say, I don't know, I defy you. I mean, there are a few examples where it's been told to answer I don't know, but in general, it's gonna give you an answer might be right might be wrong, it's going to be a trade answer. Is there an investment opportunity in AI that does explain itself does cite sources does show its work? If I was taught to do absolutely, you know, I would say most applications of AI to you know, fundamental business processes, stochastic optimization and supply chain supply, network risk, predictive maintenance, Smart Grid analytics, integration of renewables, the every one of these where we're using supervised and unsupervised learning models, they come with an entire evidence package. Okay, that explains exactly what were the factors that lead us to this decision that suggests you should replace this engine on this jet. Okay, in the next in the next 100 hours, or you should replace this transformer in Northern California, before it explodes. You know, burns 2 million acres kills 300 people, okay? And believe me, this happens in Southern California, like, every two days, okay. I mean, it's even, it's unbelievable. So but it was so when we're doing using supervised learning and unsupervised learning models, absolutely. We can come we have explainable evidence package who's everyone? It's when we get off into deep learning, okay in AGI where they become an unexplained unexplainable Now, are there ethical applications are unexplainable AI? Yes. Okay. Let's think about target identification. Is it a 737? Or is it a MiG? Okay. Okay, is it a melanoma? Or is it not? Now, if we can prove mathematically to four nines, okay, that this, okay, that this deep learning model is mathematically correct to four nines. I mean, hard stop is ethical. Okay. I mean, it goes. So this idea that all AI needs to be explainable, which is on the front page of every technology companies inside of their annual report, and none of them really believe it. Okay. There are applications for deep learning and unexplainable AI. They're totally efficacious and ethical. But then there's, there's a lot others that are kind of problem I would offer. There's one company specifically I back three years ago called elemental cognition. And the founding team was the founding six members of the IBM Watson. We all remember IBM Watson team and they have become frustrated at IBM and had become frustrated with exactly this issue of we can get answers but we have no idea how the black box comes up with the answers. So what they've been doing the last couple of years is continuously building technology, where a patient receives a prescription for these three drugs by the doctor, that AI can go in and say, here's why we chose these three drugs, and not x. The good news, it's improving and tracking wonderfully. The bad news, the computer in terms of the kinds of reasoning and answers it gives, is currently operating at a second grade level, we think we're gonna get to third or fourth grade, in the next couple of years. But for many projects, particularly around medicine, and these are being tested in three or four of the best New York hospitals, it's making a profound difference for the doctors, the nurses and the patients. But here's where I want to challenge the group. Because to Tom's point, is it better to have another two nines there of accuracy? Or is it better to be able to say, at a second grade level, here's why I made this pretty good decision with some things like this is really the debate, or is that a false dichotomy? Do we have to choose? It sounds like, in many cases, we do have to choose? I'm not sure. I need it to be bold. If you could prove with mathematical certainty that it's right to four nines, maybe I don't think there's an ethical issue that's better than a human being is going to do it. Okay. Is it a bigger? Is it a 737? Is it metastatic or not? And if you can do it to four nines, I mean, I don't think we're anywhere near any ethnic walls, I will comment on this idea that we have the companies feel like they need boards of emphasis. Okay, guys, I think that is a cop out. Okay. I mean, that's what your mother was for. Okay, if you don't know the difference between right and wrong, okay, there's something wrong. Okay. If you need a board of ethicists to tell you the difference between right and wrong, there's, I mean, that's, that's a little creepy, guys. So I just want to comment on that in the in the earlier point, which is, there may be scenarios where it's mathematically correct. And I'm okay with that, right, I would certainly like four nines as metastatic or not just better than your doctor, it's better than my doctor can do. But there's also needs to be some transparency around that. So that I have the opportunity to know how those decisions are made. I am okay with the system saying, Not really sure how we got to this decision. But mathematically, we feel very strongly about it. You know, we're four nines. And just just so you know, that's where we are. And frankly, as your doctor, it's better than what I'm going to be able to tell you. And I want to add Oh, well, I don't want to cut you off. Yeah, no. And then I don't know, I was gonna make a comment on your next point. And then I totally forgot about it. If it comes to you. I will jump in. Yes. I want to like, Are we okay, if it's four nines for you, and three nines for Lauren? And we don't know why. It's a great question. For an AI is better than a human being can do. A hard stop. But does it matter? If it's not explainable? We're not going to know. We might know it's not working as well, for women, you know, a melanoma, you're it's perfect. This doctor can explain, okay, why he or she believes this cancer has metastatic metastatic is let me tell you, that doctor can't explain it. No, but I am concerned, they're going to be able to tell it better on white skin and dark skin. And yes, if they can, you know, and that can be a problem with explainable or not. But if it's not explainable, we're not going to know why. And we're never going to improve it. And certainly what we've seen with facial recognition and other things is because that's where the data is there going to be better with certain groups. And this is not something that we're anywhere near fortnight's. Okay. In other words, we're not anywhere near right, something that everybody knows how to game, you know, so like MITRE Corporation, when they came up with that lapel pin, they will game, every facial recognition algorithm that is out there and identify you as the CEO of mitre. Okay, and so those that's easily gamed, well documented. Yeah, I would come at it. We need both the very deep, excellent analytics. For me, it's not acceptable as one person for whether it's Google or Bing, whatever we want to use, the results get spit out. And there's no explaining the reasoning behind when you're doing searches for where to pick up DoorDash. That's one thing when you're talking about a cancer patient, where the doctor already has limited time to care for that patient. And the nurses are overstrained and they're heroic, of course, having abilities for the technology To outline here is why this prescription is being recommended, or here's why chemotherapy at this point is, in our view, the right way to go. And we are starting to see the emergence of some absolutely blow away technologies we'll get, which we'll get right at the heart of reasoning. And then the final point, no, really, I think is really where they're gonna play, Jim, and I know you're an expert at this, but they're going to assist that doctor making a decision. So this will be AI, where we're informing a better informed visit. So are we all in agreement, and then Lauren gets the last word, because I've now cut her off twice. I have to just one word. One word on the biases. I mentioned, how important is to me to have female leaders, underrepresented minorities, and each one of these startups for the data that I'm licensing from Memorial Sloan Kettering, MD Anderson, UCSF. I, as the investor insist, we want data covering different ages, male, female, underrepresented minorities, so that we're starting with datasets that are heterogeneous. Lauren, you get the last word? Well, that's a big burst. Oh, no, no. You know, once again, thank you for insisting on that data. Because, you know, my level of trust of a system that I don't fully understand, increases dramatically with four nines, and then it increases more dramatically if I know that the data that the train to that system is representative and diverse. My comment was that I had forgotten earlier was your question about your comments about our external ethics boards, or, you know, supplementary ethics boards? And it gets back to the first question that we all sort of have tackled, it is not enough for companies to leave the wrong and right decisions to a mother or to an ethics board, right, we all have to be accountable in this system. And again, Jim, I'll give you enormous amount of credit for being accountable in those investment decisions, you're making intelligent decisions that you had a conversation with the Secretary of the Army, it's a lot less expensive to not do it, then then it goes to sit in front of Congress. And that's a smart decision to make because it wasn't the right decision. I don't know where all of this is going. I don't know what the answers will be. What I do know is shirking responsibility for making responsible decisions about the tools that we are developing, and the applications of those is something that all of us carry from the very first investor to the end user. And as this conversation continues, I hope we continue to have these debates with lots of different perspectives. Because just like the data, if we're only hearing from one or two groups, we're going to end up making the wrong decisions. Well, I can't sum it up any better than Lauren just did. Thank you all. Before we go. Kay, from Kay Firth Butterfield from the forum is going to give us all I'm sure some homework and how we keep this conversation going. And as we always like to do here, hopefully take it from a nice conversation and important conversation. I hope you agree this was a great one, and turn it into some action. So thank you all for attending. But before we go, Kate, join us. Thank you so much. And thank you also to the panelists for a fascinating one hour. So before we before you do go responsible AI has been figuring on the forums agenda since 2017. And it this panel reflects one of the pieces of work that we're doing with VCs and investors to think about where responsibility lies in that in that continuum. So we've kicked off really well today with all the comments. So if you're interested in our work, and interested in joining this particular work if you're an investor or VC, please join us. You can find me Keith Butterfield on top link. But there are lots of tools that we've already developed and lots of other work that we're doing. If you're interested in it. Please join us. Thank you. 

